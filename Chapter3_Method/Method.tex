%\setcounter{chapter}{2}
\chapter{Numerical Methods} \label{ch:num_methods}
This section introduces the computational methods used in generating the numerical experiments conducted in this thesis, starting with a short introduction to artificial intelligence. This is followed by a brief introduction to the biological mechanisms the algorithms in this study draw inspiration from. This helps to gain insight into possible applications of different structures.
The task of forecasting in time and space requires two types of intelligence. One is computer vision, to understand the spatial relation and use the underlying physical properties. The other is sequential modelling to understand the temporal evolution.

Two approaches will be explored: Autoregressive models (AR) and Convolutional Long Short-Term Memory Network (ConvLSTM). The \acrshort{ar} model describes a time varying process, depending linearly on its previous values. The \acrshort{convlstm} approach is used to find a non-linear relation that describes phenomena varying in both time and space.
The aim of this study is to determine whether the aggregation of linear models, or the more advanced non-linear model are better at predicting the complex cloud phenomena varying in time and space.

%The popularity of \acrshort{dl} can be partly explained by its flexibility. This flexibility allows deep learning to be applied across many domains. The algorithms discussed here are simply a mathematical framework for learning model representations in data. The process of training is repeated until the network reaches an acceptable performance. In other words \textit{the extent to which this potential can be exploited is limited to the effectiveness of the training procedure applied} and also the data its provided. 

\section{Artificial Intelligence} \label{sec:ai}
\input{Chapter3_Method/TiKZ/subcategories_AI}
In encounters with geoscientists the author often gets the question: \textit{What is the difference between machine learning and artificial intelligence?} The short answer is: they are not different fields, but \acrshort{ml} is a subfield of AI. Algorithms developing its own ``knowledge'' from supplied examples fall into the category of ML and not the base category of AI. ML is distinct in that it attempts to deduce rules and go beyond human intuition using a complex net of interactions. 

In fact, it is worth mentioning that there is a subfield of \acrshort{ml} known as \acrshort{dl} (see graph in Figure \ref{fig:subcategories_AI}). 
\acrshort{dl} is at the frontier of AI research, with many recent advances being made in this subfield. The popularity of \acrshort{dl} can be partly explained by its flexibility. This flexibility allows \acrshort{dl} to be applied across many domains. The algorithms discussed here are simply a mathematical framework for learning model representations in data. The process of training is repeated until the network reaches an acceptable performance. In other words, the potential is limited by the data and the effectiveness of the training procedure applied.

\input{Chapter3_Method/TiKZ/one_layer_mlp}
\acrshort{ai} in general and \acrshort{dl} in particular emerged from considerations of perception and cognition in biology. Many of the \acrshort{dl} network architectures draw inspiration from the human brain. The architecture of \acrshort{dl}, while distinct from biological computing, is named such that concepts in neuroscience and computing can be treated analogously. For example using building blocks such as nodes (artificial neurons), weights (connections between nodes), rules of signal propagation, activation (transfer function) and learning algorithms (training algorithms).

Figure \ref{fig:one_layer_mlp} illustrates a simple artificial neural network. The circles illustrate nodes (neurons). Nodes belonging to the same layer is shown in one colour. Arrows illustrate weights, the connections between the layers. The figure shows that nodes belonging to the same layer are not connected, but nodes in consecutive layers are connected with weights. 

Sequence modelling draws parallels to the human memory. This type of modelling requires information about earlier stages, retained in memory. Simple models have one memory centre. Drawing inspiration from the brain, other more complex models make the distinction between a short term and a long term memory centre.
Finishing others' sentences is a simple task for humans. \textit{The clouds are in the \ldots sky} (\cite{colah_blog_post}, should not come as a surprise to anyone.
% Finishing sentences for others is a trivial task for humans. The reader should not be surprised by the following \textit{the clouds are in the \ldots sky} (\cite{colah_blog_post}).

AI started with the idea of automating tasks normally performed by humans. Three factors determine advances in the field of AI: data, hardware, and algorithms (\cite{chollet_book}). This explains why there often is a significant time gap between an idea and breakthroughs in the architectures and results. Convolution neural networks (CNN), for example, were conceptually developed in the 80s (\cite{fukushima_neocognitron:_1980}), but a lack of sufficient computing power (hardware) kept their use in hibernation until 2012, when a \acrshort{cnn} (AlexNet) won the ImageNet challenge, an image recognition contest (\cite{AlexNet}).

Geoscientists may be more familiar with the concept of ``calibration'' when it comes to statistical models, which essentially is the same process. In the context of deep learning, ``deep'' refers to the number of layers contributing to a network. DL expands the ideas from ML using deeper networks, \textit{i.e,} more layers, enabling networks to capture a more complex relationship between input and output variables.

\input{Chapter3_Method/TiKZ/multilayer_mlp}
Figure \ref{fig:multilayer_mlp} illustrates a deeper version of the network displayed in Figure \ref{fig:one_layer_mlp}. A layer is a set of nodes. The connections between the layers are the trained units, also known as weights. 

``Intelligence'', in the context of artificial intelligence, is still a topic of debate. Traditionally, a machine would be considered intelligent if it could beat a human at a given task (\cite{Chollet2019OnIntelligence}). For computer chess, this was achieved in 1997 when IBM's DeepBlue beat Garry Kasparov. Researchers had learned how to build a ``rule-based'' chess-playing AI, but not a program that could generalize to anything beyond similar boardgames. In retrospect, scientists have realized that most architectures are not well matched to human intelligence. 

There are several different types of machine learning, each suitable for solving different tasks. Figure \ref{fig:machine_learning_categories} shows the types of ML and their subcategories. These subcategories also exist for deep learning, the only difference being the number of layers used.
% Dimensionality reduction has been used by climatologist for decades in order to remove seasonal variation \textbf{cite Benestad}. 
\input{Chapter3_Method/TiKZ/graph.tex} 

\begin{itemize}
    \item \textbf{Supervised learning}: part of machine learning concerned with learning the relation between input data, x and labelled data, y.
    \begin{itemize}
        \item Regression\\predict continuous values. Replicating a function.
        \item Classification\\discrete, since it assigns a category to the input.
    \end{itemize}
    \item \textbf{Unsupervised learning}: Detecting patterns in unlabeled data.
    \begin{itemize}
        \item Clustering\\Grouping a set of data points into a predescribed number of groups
        \item Dimension reduction\\Reducing the number of random variables under consideration.
    \end{itemize}
    \item \textbf{Reinforcement learning}: Goal oriented algorithms.
\end{itemize}

\section{Artificial Neural Networks} \label{sec:artificial neural networks}
Because of the interdisciplinary nature of this thesis, this section provides a thorough walk through the relevant algorithms using the computational graphs, and relevant equations. 

Artificial neural networks (\acrshort{ann}) are composed of nodes (artificial neurons) and weights. Returning to Figure \ref{fig:one_layer_mlp}, it illustrates nodes as circles and weights as arrows. It is an example of a 2-layer \acrshort{ann}. The nodes are structured in layers, illustrated using different colours. The input layer contains four input nodes, the hidden layer five nodes, and the output layer three nodes. The dimensions of the input and output layers are determined by the task at hand. The number of hidden layers and the number of nodes are tunable parameters, called hyperparameteres. Nodes of one layer are only connected to the the nodes of the following layer. Weights are the relative strength of the connections between nodes in neighbouring layers. Large networks of these simple neurons are able to perform complex calculations.
\input{Chapter3_Method/TiKZ/activation_mlp}
\begin{figure}
    \centering
    \includegraphics[scale = 0.4]{Chapter3_Method/figs/activation_functions_and_derivatives.png}
    \caption{Activation functions and their derivatives.}
    \label{fig:activation_function_example}
\end{figure}

Figure \ref{fig:activation_one_node} shows the computation which takes place in a node in the hidden layer, focusing on a circle in the middle column in Figure \ref{fig:one_layer_mlp}. The sum of the weighted inputs and bias are sent trough the activation function, $g$, producing the activation. This function, $g$, is a hyperparameter, set before the training starts. Popular choices are rectified linear unit (ReLU), Sigmoid function  ($\sigma$) or hyperbolic tangent (tanh), their graphs are shown in Figure \ref{fig:activation_function_example} and their mathematical expressions in Equations \eqref{eq:ReLU}, \eqref{eq:sigmoid} and \eqref{eq:tanh} respectively. It is called Sigmoid function, named after the greek letter sigma, shaped like an S. 
\begin{equation} \label{eq:ReLU}
   ReLU\left(x\right) = 
     \begin{cases}
       \text{x,} &\quad\text{if x} \ge 0\\
       \text{0,} &\quad\text{else}
     \end{cases}
\end{equation}
\begin{equation} \label{eq:sigmoid}
   \sigma \left( x \right) = \frac{1}{1 + e^{-x}}
\end{equation}
\begin{equation} \label{eq:tanh}
   tanh\left( x \right) = \frac{e^x - e^{-x}}{e^x + e^{-x}} = \frac{e^{2x} - 1}{e^{2x} + 1}
\end{equation}
Equation \eqref{eq:activation_hidden_pass} describes the activation of a node in a arbitrary layer, L. $b_L$ denotes the bias, $w_L$ is the weights matrix. and $n_L$ is the number of  nodes. $g_L$ denotes activation function in a arbitrary layer.
%For regression problem, $g_o$ is linear like.
\begin{equation} \label{eq:activation_hidden_pass}
    \textbf{a}_L = g_L\left(\sum_{i=1}^{n_L} \textbf{W}_{L, i} \textbf{x}_i + b_L\right)
\end{equation}

Repeating the procedure for the next layer, $L+1$, the activation, $a_L$ from the previous layer is weighted and passed trough the activation function, $g_{L+1}$, generating the activation, $a_{L+1}$. In a forward pass, this is repeated for all layers, until the output layer is reached. Adapting Equation \eqref{eq:activation_hidden_pass} to the example in Figure \ref{eq:activation_hidden_pass} can be done by inserting $L=1$ and $n_L=4$.

The choice of activation function, $g$, in the output layer is task specific. Regression problems use linear activation. Classification problems need functions able to discriminate between the number of classes.

Backpropagation is the fundamental mechanism used in ``teaching'' neural networks, as first appreciated in its full importance in \citeyear{RumelhartBackProp} when it was published by \citeauthor{RumelhartBackProp}. The trick is to use the performance metric as a feedback signal to adjust the weights in the direction of the lowest loss score for the current example. A training instance is passed trough the network producing an output (red node). The network's output error is computed as the difference between the produced output and the corresponding targets. For each consecutive layer, moving in reverse from the output to the input, the contribution from every connection between adjacent layers is computed.
For a more mathematical description of the backpropagation algorithm see \citepaper{nielsen_back_prop}.

\subsection{Convolutional neural networks} \label{sec:convolutional neural network}
%\textit{According to the philosophy underlying deep learning approach, if we have a reasonable end-to-end model and a sufficient data for training it, we are close to solving the problem}. (Shi et. al., 2015). 
Computer vision is a field of artificial intelligence concerned with interpreting the visual world. One popular structure for visual tasks is the convolutional neural network. %Its said to resemble the visual cortex, the centre in the brain which processes the visual information. 
\input{Chapter3_Method/TiKZ/2D_image_to_3D_tensor}
Computers see images as a grid of numbers, often decoded in red, green and blue (RGB) channels. Figure \ref{fig:2D_image} shows the transformation of a two-dimensional image to a 3-dimensional tensor. The ``P'' shows the connection between one pixel (``picture element'') and a volume. Each of the grid cells (pixels) contains the signal from the colour decoded into values ranging from 0 to 255. The machine needs to learn how to extract the necessary information about these pixels to perform a task. More layers increase the model's ability to extract these complex structures, resulting in improved model performance. 
\input{Chapter3_Method/TiKZ/convolution}
Figure \ref{fig:convolution} shows the mathematical operation convolution as the sum over element-wise multiplication of the filter and input. The filter is blue, this is placed over the filled green section, producing the red output pixel. The entire red grid is called a feature map (output map). The green grid is the input, overlaid with blue indicating the pixels contributing to the activation, of the red pixel. In Figure \ref{fig:convolution} this would be the value 4. \textit{Receptive field} is known as the pixels contributing to the activation in a pixel (i.e. the value) (\cite{Luo2016UnderstandingNetworks}). For instance the receptive field of the shaded red pixel is the shaded green submatrix.

\input{Chapter3_Method/TiKZ/convolution_connection_between_layers}
Convolving a filter over the input image generates a feature map, a 2-dimensional activation. If it happens to be the last layer, it is common to refer to the results as the output instead, although this is merely a difference in terminology. Figure \ref{fig:convolution_padding} shows a 2D-convolution with filter of size $3\times 3$. Filters are often square (not a strict requirement), and the height $f_h$ and width $f_w$ are odd numbers. The origin is the position of the kernel which is above the current output pixels. The connections between the layers are intended to illustrate the part contributing to the pixel, as well as highlighting the receptive field. In order to include the outermost pixels, the input area is padded with zeros around the edges (grey boarder). 
\input{Chapter3_Method/TiKZ/2_layer_convolutional}

Working with \acrshort{rgb} images requires 3D convolution; since the dimensions of the input determines the dimensions of the convolution, it is commonly referred to as simply convolution. As mentioned earlier, neural networks are structured as a stack of layers. Each layer is again a stack of channels or feature maps. The output from the previous layer becomes the input to the next layer. Feature maps, activations, and outputs are all the result of a convolution, produced at different points within a neural net. The activations are computed based on an input volume, including information across channels. A 3D convolution collapses information on multiple colours into a single value.

Figure \ref{fig:conv_layers} shows a two layer convolutional neural network trained on \acrshort{rgb}-images. The input layer is an RGB-image. The first convolutional layer has seven channels (feature maps), these are produced by seven filters. Filters are trained to extract useful features. The second convolutional layer is produced by five filters, all convolving layer 1. This is a simplified network, made shallow for for the purpose of illustration; a functional CNN would require many layers to extract useful information from an image. %Networks are usually a lot deeper.

Given raw input (\textit{i.e,} normalized images), the first layers detect low level features like edges, corners and circles. Later layers assemble the features to more complex structures like houses or dogs. The dashed volumes represent the receptive field for different pixels, illustrated as circles. Since each of the layers depend on the previous one, the receptive field of a node, ``P'' depends on a large portion of the input image. Small filters allow you to focus on small features in the data, while larger filters allow you to identify coarser relations.

Unlike the fully connected neural network layers (see Figure \ref{fig:one_layer_mlp}), the nodes in the output layer are not connected to all the input nodes, only the nodes within their receptive fields. The filters contain the trained units. Its dimensions determine the size of the feature it can detect. One filter convolves the entire image, searching for a single feature.  When it finds this particular feature it activates, propagating this signal into the feature maps.

\subsection{Recurrent Nets} \label{sec:reccurent_nets}
% Recurrent betyr tilbakevendende
% Sequential modelling has had a great success in applications such as machine translation and speech recognition 

\input{Chapter3_Method/TiKZ/rnn}
A recurrent neural network (RNN) is a class of artificial neural networks developed for studying patterns in sequential data such as time series, audio, or text. Figure \ref{fig:rnn} shows the structure of a simple RNN. In very simplified terms, the recurrent unit, $A$, receives an input, $x_t$, produces an output, $y_t$ and passes hidden state, $h_t$ back to itself. The hidden state contains the information about what you have learned so far. The output at each time step is dependent on the previous inputs. 

\input{Chapter3_Method/TiKZ/rnn_unrolled}
Figure \ref{fig:rnn_unrolled} shows the recurrent network unrolled in time. This way of structuring it resembles the earlier structures like ANN (see Figure \ref{fig:one_layer_mlp}). The connection between the nodes %in this kind of networks 
are a directed graph along a temporal sequence. The hidden state from the previous step is fed into the next, here the recurrent units, $A$ can be considered a copy. For each time step it is fed with new examples, $h_0$ is only dependent on $x_0$, while $h_t$ is dependent on the entire training sequence $x_0, x_1, \cdots, x_t $. This example shows a one layer recurrent network. All time steps are passed through the same node, updating the connections between the input, output and hidden states. In this way, the RNN reuses the weights for all time steps, performing the same task on all inputs along the sequence. This reduces the complexity of parameters and in turn lowers the risk of overfitting, obtaining a more general relation between input and output.
%The "memory", $h_t$, stores the useful information from the training sequence $x_0, x_1, \cdots, x_t $ needed to make a prediction
%are a directed graph along a temporal sequence. The hidden state from the previous step is fed into the next. $h_0$ is only dependant on $x_0$, while $h_t$ is dependent on $x_0, x_1, \cdots, x_t $. This example shows a one layer recurrent network. All time steps are passed through the same node. The RNN reuses the weights on the input and hidden states for all time steps. Let t denotes the length of the training sequence. The "memory" stores the useful information from $x_0, x_1, \cdots, x_t $ needed to make a prediction, performing the same task on all inputs along the sequence. This reduces the complexity of parameters and in turn lowers the risk of overfitting, obtaining a more general relation between input and output.
% It is used to predict the next word in a sentence or the next tone in a song.  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Learning long term dependencies can be challenging and is done by backpropagating the error signal thought the network. Working with longer sequences, the error signal tends to approach zero or infinity. Exploding gradients can cause the weights to oscillate. Learning from small or vanishing gradients takes a very long time, and might not produce a useful outcome at all. 
%More advanced forms of recurrent nets control the information flow using gates. \textbf{cite 1997 and cite 1999 learning to forget.}

\subsection{Long Short-term memory network} \label{sec:lstm}
In order to address challenges in predicting long sequences presented in the previous section, \citeauthor{Hochreiter1997LongMemory} created the \acrfull{lstm}. Their design, documented in a paper from \citeyear{Hochreiter1997LongMemory} (\cite{Hochreiter1997LongMemory}), outperformed previous memory networks by regulating the flow of information provided to a recurrent network at each time step.
They propose a new method for learning %an approach for constant error flow 
in order to alleviate the issues with exploding or vanishing gradients. This approach is called constant error flow. 

The original memory cell contains input and output gates. A gate is a structure that can be opened or closed. Having values raging from 0 to 1, it truncates the noise signal from the input and the output. \citeauthor{lstm_learning_to_forget} suggested in \citeyear{lstm_learning_to_forget} to add an additional gate, the forget gate. The idea was to enable the \acrshort{lstm} to reset parts of its own memory. Resetting releases internal resources and enables even more learning. In very simplified terms, the forget gate learns which part of the cell state, the long-term memory, it should forget. The input gate learns the information from the input it should add to the cell state. The output gate learns which information it should pass to the output. 
% This figure appear to long down on the list.
\input{Chapter3_Method/TiKZ/subplot}
The assembled memory unit is displayed in Figure \ref{fig:lstm_unit}. The information flow thought the cell is regulated by three gates; the forget gate (see Figure \ref{fig:forget_gate}), the input gate (see Figure \ref{fig:input_gate}) and the output gate (see Figure \ref{fig:output_gate}). These gates are neural networks. 

The long-term memory is shown in Figure \ref{fig:cell_state_information_flow} and the short term memory is referred to as the hidden state. The cell state is affected by some linear interactions, this is very simple, thus the flow often remains unchanged. The hidden state is the output passed to the next cell. Structures like gates regulate the flow of information. 

The gates are neural networks layers with a particular activation function. The Sigmoid-function discussed in Section \ref{sec:artificial neural networks} truncates the output from the gates to range between zero and one. Recall, Figure \ref{fig:activation_function_example} shows the sigmoid and tanh functions. Zero represents a closed gate, while one describes a fully open gate. At each time step in the sequence the \acrshort{lstm} receives input $x_t$ and the previous hidden state, $h_{t-1}$. These are passed trough all gates.

% The forget gate
Making a prediction requires the forward propagation of information through the network. Figure \ref{fig:forget_gate} shows that based on the new input and the previous hidden state, the forget gate determines which instances from the memory to remove. Regulating the information that stays in memory frees up space, allowing the network to learn new things. The weight of the gate, $W_f$, is initialized to 1, thus it cannot forget anything until it has learned to forget. Exhibiting the same behaviour as the original \acrshort{lstm} units. 

% The input gate 
Figure \ref{fig:input_gate} shows two processes, one determining the candidate information based on the input and the other the computations of the input gate. The candidate information is filtered by the multiplicative input gate. This determines what information to add to the cell state.

Figure \ref{fig:update_memory} shows how the cell state is updated. Using multiplicative gates, first the forget gate removes information. Then the output from the input gate adds the useful information from the input to memory. The input gate regulates what information to store from the input. The aim of the input gate is to clean the input by reducing the noise signal. These computations are also shown in Figure \ref{fig:input_gate}.

Figure \ref{fig:output_gate} illustrates how the output gate gets updated. Passing the cell state through the function $tanh$, it is given a value in the range from -1 to 1. The output gate determines what to remove from the cell state and pass as the hidden state. This gate aims to remove noise from the output, preventing misrepresentations of the hidden state (short-term memory). This forces the hidden state to always take values in the range minus one to one (\cite{Hochreiter1997LongMemory}).  In summary, at each time step some memories are removed and others are added. 

% Finish with this
The process of training is repeated until the network reaches an acceptable performance. The principle of learning is the same as for the simpler architectures. However, the mathematical description of the backpropagation algorithm gets more complicated. The reverse pass measures the error gradients over all connections traversing backward to the input layer. Like before, based on the error signal the weights are adjusted in the direction of the lowest error.

\clearpage
\subsection{Convolutional LSTM}  \label{sec:convolutional_lstm}
A variant of the \acrshort{lstm} network is the \acrfull{convlstm}, which was originally developed for the application of precipitation nowcasting in 2015. This architecture has the potential to solve problems varying in time and space. The difference between this and the general LSTM is that the standard \acrshort{ann} (see Figure \ref{fig:one_layer_mlp}) is replaced by \acrshort{cnn} (see Figure \ref{fig:convolution_padding}). This allows the \acrshort{lstm} network to support multi-dimensional data, capturing its spatiotemporal structure. 
\input{Chapter3_Method/TiKZ/inside_conv_lstm}

Preserving the structure from Figure \ref{fig:lstm_unit}, and making small changes to the equations used to forward propagate the input, the multiplicative gates are now replaced with convolution. 
Figure \ref{fig:inside_conv_lstm} shows the dimensions of states and input, the inner structure, in a \acrshort{convlstm}. 

%% I have attempted to reduce the white space between the equation, but have not been able to do so without losing the possibility to label and refere to eah component.
Equations \eqref{eq:CLSTM2_forget_gate} - \eqref{eq:CLSTM5_hidden_state} describes the forward propagation through a \acrshort{convlstm}. 
\begin{equation} \label{eq:CLSTM2_forget_gate}
        f_t = \sigma \left( W_{xf}*x_t + W_{hf}*H_{t-1} + W_{cf}\circ C_{t-1}+b_f \right)
\end{equation}
\begin{equation} \label{eq:CLSTM1_input_gate}
    i_t = \sigma \left( W_{xi}*x_t + W_{hi}*H_{t-1} + W_{ci}\circ C_{t-1}+b_i \right) 
\end{equation}
\begin{equation} \label{eq:CLSTM3_cellstate}
        C_t = f_t \circ C_{t-1} +i_t\circ tanh\left( W_{xc}*X_t + W_{hc}*H_{t-1} + b_c \right)
\end{equation}
\begin{equation} \label{eq:CLSTM4_output_gate}
        o_t = \sigma \left( W_{xo}*X_t + W_{ho}*H_{t-1} + W_{co}\circ C_{t}+b_o \right)
\end{equation}
\begin{equation} \label{eq:CLSTM5_hidden_state}
        H_t = o_t \circ tanh \left( C_t \right)
\end{equation}
Here $\circ$ denoted the Hademand product, which is a component wise multiplication, and * is convolution. For an arbitrary time step, $t$, $H_{t}$ denotes the hidden state and $C_{t}$ is the cell state, $\sigma$ is the sigmoid function (see Equation \eqref{eq:sigmoid}), $tanh$ the hyperbolic tangent (see Equation \eqref{eq:tanh}), and $W_{\text{component}, \text{gate}}$ denotes the trained weights of components and gates (\cite{precip_nowcasting}). 

\subsection{Padding} \label{sec:padding}
% Add equation to calculate how much zero padding is needed to make a prediction of the same size.
As mentioned related to Figure \ref{fig:convolution_padding}, the convolution operation shrinks the dimensions of the feature map, according to Equation \eqref{eq:output_size}. The degree of shrinking depends on the filter size, $f\times f$, padding, $p$ and stride, $s$. Stride determine how you convolve around the input volume. It is the step length between applied filters. For an input of dimensions $n\times n$, the resulting output dimension, $o\times o$ is given by Equation \eqref{eq:output_size}.
\begin{equation} \label{eq:output_size}
    o = \frac{n+2p-f}{s} + 1
\end{equation}
Padding zeros along the edges has an additional benefit of including the signal originating at the boundaries. For some applications it is useful to have the same shape of input and output. This is called ``padding same''. Equation \eqref{eq:padding_same} calculates the amount of padding necessary to preserve the dimension of the input volume. 
Derived from Equation \eqref{eq:output_size} inserting $o=n$ and solving for $p$.
\begin{equation} \label{eq:padding_same}
    p = \frac{n\left(s-1\right)-s+f}{2}
\end{equation}

\section{Autoregressive Models} \label{sec:ARmodels}
In the following discussion, these conventions are adopted. Typographical emphasis is used to distinguish between dimensions, $y_n$ denotes a discrete value at position or time, $n$, the vector, $\mathbf{y}$ and $\mathbf{Y}$ denotes the matrix. $\mathbf{X}$ always contains the input data, and $\mathbf{y}$ always contains the predicted. The markers $\tilde{ }$, $\hat{ }$ and $\bar{ }$ can be used in combination with the above, describing the $\Tilde{\mathbf{y}}$ denotes the desired value, the predicted $\hat{\mathbf{y}}$ and the mean of $\mathbf{y}$, $\bar{\mathbf{y}}$.

The \acrshort{ar}-model is a form of linear model where values from previous time steps are included as predictor variables. In discrete form it is described by Equation \eqref{eq:AR_traditional} and in matrix form by Equation \eqref{eq:AR_traditional_matrix}, here a prediction at time, $n$, $\hat{y}_n$ is the linear combination of the values at $i$, earlier time steps, $y_{n-i}$, their corresponding weights, $\beta_i$, and $\beta_0$, the bias (intercept), corresponding to the intersection of a function on the y-axis. 
%Equation \eqref{eq:AR_traditional_matrix} formulates the matrix equation.
\begin{equation} \label{eq:AR_traditional}
    \hat{y}_n = \beta_0 + \sum_{i = 1}^{N} y_{n-i} \beta_{i}
\end{equation}
%Rewritten into a matrix equation, 
\begin{equation} \label{eq:AR_traditional_matrix}
    \hat{\mathbf{y}} = \mathbf{Y}^T \mathbf{\beta}
\end{equation}
Expanding the traditional AR model to include other predictors, $x_i$, yields the expression,
\begin{equation} \label{eq:AR_expression}
    \hat{y}_n = \beta_0 + \sum_{i = 1}^{N} y_{n-i}\beta_{i}+ \sum_{j=1}^p x_j\beta_{j+p}
\end{equation}
Here $p$ denotes the number of predictors, and $\beta_{j+p}$ the corresponding weights. The other symbols are described above referring to Equation \eqref{eq:AR_traditional}. 

The weight indices might seem unnecessary complicated at first, but ease the transition to the vector equation, $\mathbf{\beta} = [\beta_0, \beta_1, \ldots, \beta_i, \beta_{i+1}, \ldots, \beta_{p+i}]^T$. The corresponding input matrix, $\mathbf{X} = [1, y_{n-1}, \ldots, y_{n-i}, x_0, \ldots, x_p]$. 
This can be formulated as a least-squares problem, and the analytical solution to this optimisation problem is found by minimising the \acrfull{mse} loss, 
\begin{equation} \label{eq:mse_loss}
    L (\tilde{y}, \hat{y}) = \frac{1}{n} \sum_{i=0}^{n-1}(\tilde{y}_i-\hat{y}_i)^2
\end{equation} 
where $\hat{y} = \mathbf{X}^T \mathbf{\beta}$. Equation \eqref{eq:AR_solution} describes the optimal solution $\mathbf{\beta}$. Inserting Equation \eqref{eq:AR_traditional_matrix} into \eqref{eq:mse_loss}, solving Equation \eqref{eq:diff_eq} with the respect of $\beta$ yields the solution presented in Equation \eqref{eq:AR_solution}.  
\begin{equation} \label{eq:diff_eq}
    \frac{dL}{dX} = 0
\end{equation}
\begin{equation} \label{eq:AR_solution}
    \mathbf{\beta}  = \left( \mathbf{X}^T\mathbf{X}\right)^{-1} \mathbf{X}\tilde{\mathbf{y}}
\end{equation}
The optimal solution is the best solution based on the training data available. The analytical solution is computationally very fast, as long as the matrix $\mathbf{X}^T\mathbf{X}$ is non-singular and thus its inverse exits. For the problem considered in this study there are far more observations than the number of parameters. This is a indication that $\mathbf{X}^T\mathbf{X}$ is invertible. %Further please note that the matrix is only inverted when the parameters are estimated (model training) and not when the model later is used to make predictions.
% The code is implemented using scipys pinv to solve the problems with invertable matrices.
%Unfortunately, for many practical applications the inverse doesn't exit. The Moore-Penrose psudoinverse, $A^+$ of matrices is used to approximate the inverse of singular matrices. It is based on the foundation of singular value decomposition. The Moore-Penrose pseudoinverse exists and is unique for both square and rectangular matrices (\cite{Golan2012}). For invertible matrices, $A$, the psudoinverse becomes the inverse, $A^+=A^{-1}$.

%\subsection{Loss and Performance Metrics}  \label{sec:metrics}
\subsection{Evaluation} \label{sec:evaluation}
%A optimisation process aim to acquire a certain skill. 
Model evaluation is done based on metrics. This metric is used to determine the ability of a model to perform a certain task. Varying in space and time, the metrics used to evaluate the models in this study need to be 3-dimensional.

These metrics are set based on criteria measuring properties of the algorithm, for instance mean squared error measures the squared distance to the true value, giving a idea on how well it fits to the target. shown in Equation \eqref{eq:mse}, notice that it is not scaled. \acrshort{mse} is non-linear and numbers in the range between 0 and 1 shrink, while others grow exponentially.  \acrfull{mae} is the absolute value between the same distances, see Equation \eqref{eq:mae}. 

%The R2-score, also known as the coefficient of determination, shown in Equation \eqref{eq:r2},  determines how much of the variation in the dataset is captured by the model. The above mentioned models output volumes, and metrics are written in their three-dimensional form accordingly.
\begin{equation} \label{eq:mse}
    MSE(\hat{Y},\hat{\tilde{Y}}) = \frac{1}{n\cdot m \cdot k} \sum_{i=0}^{n-1}\sum_{j=0}^{m-1}\sum_{k=0}^{t-1}(y_{i, j, k}-\tilde{y}_{i, j, k})^2
\end{equation} 
\begin{equation} \label{eq:mae}
    MAE(\hat{Y},\hat{\tilde{Y}}) = \frac{1}{n\cdot m \cdot k} \sum_{i=0}^{n-1}\sum_{j=0}^{m-1}\sum_{k=0}^{t-1}\left|y_{i, j, k}-\tilde{y}_{i, j, k}\right|
\end{equation} 
%\begin{equation} \label{eq:ase}
%    ASE(\hat{y},\hat{\tilde{y}}) =  \sum_{i=0}^{n-1}(y_i-\tilde{y}_i)^2
%\end{equation} 
%%%%% R2 is not used anywhere in this study
%\begin{equation} \label{eq:r2}
%    R^2(\hat{Y}, \tilde{\hat{Y}}) = 1 - \frac{\frac{1}{n\cdot m \cdot k} \sum_{i=0}^{n-1}\sum_{j=0}^{m-1}\sum_{k=0}^{t-1}(y_{i, j, k}-\tilde{y}_{i, j, k})^2}{\frac{1}{n\cdot m \cdot k} \sum_{i=0}^{n-1}\sum_{j=0}^{m-1}\sum_{k=0}^{t-1}(y_{i, j, k}-\bar{y})^2}
    %{\sum_{i=0}^{n - 1} (y_i - \bar{y})^2}
%\end{equation} 
%where mean value of $\hat{y}$ is defined as $\bar{y} =   \sum_{i=0}^{n-1}\sum_{j=0}^{m-1}\sum_{k=0}^{t-1}y_{i, j, k}$. 
%$R^2$ describes how much of the variation in the dataset you are able to capture with your model. 
The absolute value or sum of squares is to avoid penalising points on the lower side of the line, it has an additional benefit of not having to deal with negative distances. 

\section{Related work} \label{sec:related_work}
Deep learning is a young field and \acrshort{convlstm} an even younger model. Few studies have been conducted within \acrshort{dl} applied to sequence modelling. The task of object detection or classification has to this date received the most attention.

The \acrshort{convlstm} was developed by \citepaper{precip_nowcasting} for the task of precipitation nowcasting. \citepaper{SunAirLSTM} applied it to the air quality forecasting problem, using high resolution data from a period up to two years. Both studies evaluate their models based on case specific metrics. % Results from model is not transmissible across problem, in this case datasets.

\citepaper{precip_nowcasting} used gridded data and the spatial dimension is $100\times 100$ after resizing it using filters to remove noise. The dataset used, named Radar Echo, has 8148 training, 2037 validation and 2037 test samples. Each sample consists of 20 frames, 5 used for input and 15 used for prediction, in other words based on five frames the model predicts 15. \citeauthor{precip_nowcasting} report that they have managed to training a model, named $ConvLstm 3\times 3-64-3\times 3-64$. The naming convention revels the models architecture. This model has two layers, both with 64 hidden states used in combination with $3\times 3$ kernel. 
Theses results are compared to a FC-LSTM-2000-2000 and a traditional model for precipitation nowcasting, the ROVER algorithmn. Both LSTM version optimise the crossentropy error of 15 prediction samples. This aimed to predict the maximum likely event. 
%\textbf{Du har ikke forklart crossentropy noen plass. A common metric in classification problems.}

\citepaper{SunAirLSTM} use a combination of distributed data. Weather data is provided in grids, and air quality observations are point measurements. The weather data volume per time step is a tensor of shape $(21 \times 31 \times 5)$. Sixteen months of hourly data were divided into sequences of 72 frames, 24 for input and 48 for prediction. %Batch size is not mentioned in the paper, but based on Figure X, where one tensor of shape $(21 \times 31 \times 5)$ is sent as input. i.e. one sample. 
They use a learning rate scheduler dropping from 0.01 to 0.001 after five epochs, and gradient clipping to avoid exploding gradients when training longer sequences. This is combined with the following kernels; $1\times 1$, $3\times 3$ and $5\times 5$. Two or three layers with either 256 or 128 hidden states. The model names are given following this structure, described using an example. The model \textit{ConvLSTM 3x3-256-2}, is a \acrshort{convlstm} model using a $3\times 3$ filter, 2 layers having the same number hidden states, 256.

%\textbf{Les igjen, hva er patch size..?}
%Include patch size of 4 making 64x64 to 16x16x16 tensors. Choice of optimizer is RMSprop 0.001 and a learning rate decay of 0.9. Performs early stopping on the validation set.


%%%%%%%%%%%%%% above here is ok

%In this works the model is trained on a small amount of data. Unlike like dataset.
%State-of-the art models 

 


%%%% summarize precipitation nowcasting 



%%%%%%%%%%% summarize the 

%A hyper parameter is a constant set before the training procedure begins. There is a mind-boggling amount of choices for hyperparameters, the initial configuration used in the conducted experiments for this project draw inspiration from this paper. 

%Deep learning is a young field and not many studies have been conducted in the intersection with geosciences. This section provide a brief introduction to some relevant studies and their findings. 
