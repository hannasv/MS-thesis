\chapter{Discussion - currently inspo}
\section{INSPO}
\begin{enumerate}
    \item No further adjustment is needed for a proper comparison.
\end{enumerate}

Siter Schubenau og si at satelitter definerer skyer basert på optical depth og at det derfor er nokså stor forskjellen på global gjennomsnittlig skydekket. I tillegg har man forskjeller på retrival algorithmns and sensors. 

\subsection{NOTES -- to be removed}
Given enough data. Accurate and high resolved measurements is important for learning physical based parametrisations from data. 

I dagen klima vet vi at skyer er vektig
Wild et al 2019 radiative budget.

Usikkerhet for fremtidig klima.
IPCC for klimafølsomhet og endringer i sky regimer. 

Manaby and Waetherall 1967 og (75?). første klimamodeller 
Hansen et al 1984.

Arrenius 1896 og tyndal 1861 fourier 1827.

cloud regimes from satelite images. What to expect in Europe. 

Figur forrig ipcc rapport. 

\begin{itemize}
    \item Sitere the earth machine. Si at machinlæring for stadig mer oppmerksomhet innenfor klimaforsning. 
    \item Snakke generelt om machine læring og artikkelen the measure of intelligence. 
    \item We’ll come back to this in section 2.1.5.
    \item Is out of the scope of this thesis.
    \item To abbreviate the notation for the cross-entropy the loss function is used, so we can rewrite eq. (6) into
    \item The distribution of values
    by feature is shown in fig. 2.
    \item Create correlation matrix using 
    \item We will keep in mind both the scores of 0.743 and 0.782, serving
    as fair baselines for a very simple, and slightly more sophisticated
    regression fit, respectively.
    \item Plotting R2 vs epoch, set ylim to 0,1. Not interresting to see where it learns.
    \item Summaries the best five architecture 
    \item A drawback of introducing more layers
    is that it increases the complexity, and thereby the chance of
    \item emphesizing a good agreement for latitudinal variation.
 \end{itemize}


Advances in making deep learning possible:
\begin{enumerate}
    %\item Data availability, internet 
    %\item Hardware, engineering science (unlike mathematics and physics where advances can be made using pen and paper) - GPUs from gaming
    %\item Flexibility of neural networks makes it useful for fields ranging from self-driving cars, face generation and cancer detection. 
    %\item Probabilistic modelling and neural nets.
    \item Each layer learn the representation of the previous layer. 
    \item Deep networks can find relations in complex datasets this removed the need for feature representations and 
    \item classification + natural language processing --> image captioning. Getting the machine to write a sentence describing the image.
    \item Bottlenecks - rediscoveries backpropagation algorithmn and gradient descent. Can take any loss surface and move down the gradient toward a minimum. 
    \item k nearest neighbour, easy to explain - one of the first classification algoritmns.
    \item convolution - 2010 - works with every perceptual task - task involving learning something 
    \item solving pde's
    \item emulating other -- increasing speed while mimicking other models.
\end{enumerate}

\section{Good phases}
\begin{itemize}
    \item  In its most simple form, the diffusion equation is given by
    \item By using a finer grid one can usually get better approximations
    \item The comparison will focus on computational time and accuracy.
    \item This was chosen after
studying the development of the loss function as a function of number of iterations
    \item and is mandatory in
more advanced architectures(e.g. residual nets) where a constant spatial
dimension is demanded.
    \item a list of examples and so forth.
    \item (I will reference to source code/project part where relevant!)
    \item out of sample precision.
    \item Learn how to create plots with a zoomed in view.
    \item sufficiently large
    \item Viktig poeng. \textit{However, both academic
researchers and practitioners alike acknowledge the
need to make tests on the actual data set that is
subject of interest, as well as dedicating time and
resources to tune hyper parameters}
    \item methods for tabular data vs images
    \item I have opted to use
    \item We have also modified our own code for a dense feed forward neural
network produced for Project 2, see
    \item Gradient methods are at the heat of every machine learning algorithms. 
\end{itemize}

\begin{enumerate}
    \item Hvorfor det er viktig - prøv uten dommedag vri.
    \item Hva du vil gjøre for å løse det -  machine læring.
    \item Hva har andre gjort for å løses det - traditionell probabilistic modelling. 
    \item Sometimes emissions of greenhouse gases are referred to as climate forcers.
    \item Forskjell på earth system models, ECM and global circulation models, GCM is that ECM includes a carbon cycle. Which is very important when studying the carbon emissions of different RCPs and SSPs.
\end{enumerate}

\begin{enumerate}
    \item How representative is the training period we choose?
    %\item politikk - machine learning velger personalisert reklame i forhold til valg.
    %\item speech recognition (google speaker)
    %\item spam filter 1990
    %\item selv kjørende buss - aker brygge 
    %\item manipulere video - at du får politikere / andre til å si ting de aldri har sagt
    %\item face generation
    \item testing (in-sample error) and validiation (out of sample error) - generalization error 
    %\item pipeline - transformations of cloud cover data. 
    %\item predicting house prices is a typical regression task. Predicting if a person will default on its loan is another one. 
    \item clustering and classification as examples on mnist (overused dataset)
    %\item Stuff on downloading data and installing the enviornment can be called \textit{setting up your workspace -- > downloading data}
    \item Look at the correlation in the data. Pearson correlation? Someone else correlation?
    \item \textit{This plot reveals several things. First, the correlation is very strong. Second, ... }
    \item \textit{You will often gain good insight on the problem by examining data.}
    \item Ensamble methods in climate models and machine learning. It true that for both domains the model mean usually outperform the single model.
\end{enumerate}

\section{Future work}
In future work it would be interesting to asses how data driven parametrisation compare to the existing parametrisaions available in the state of the art climate models. Here both the temporal and spatial resolution is a lot coarser. Other data sets could be considered. The masks in other data sets are computed based on more channels than in METEOSAT but the temporal resolution is a lot worse. 


\textbf{From the introduction.}

%Logistic regression and Naive Bayes classifiers are exampls of algorithmns that predates computers, but are still very useful to this day. 
Internet continuous to provide large amounts of data from Wikipedia, Flicker (tagged images) and YouTube. Technological advances such as the \acrfull{gpu} allow for fast computations. It was originally developed for gaming. The invention of the interface CUDA allows performing heavy computations. This did wonders for machine learning.
%Advances in computational powers, such as graphical processing units, GPU's \textit{provide a environment/platform=os to learn in/on}. These where originally develop for the gaming industry, but in 2007 they realised a interface called CUDA (2007) which allows for computing \textbf{find a up to date cost and flops (floating point operations per second)}. \textbf{siter Chollet bok}
\\ \\ 
For clarity, the deep in deep learning refer to the number of layers. Moving from shallow networks to deeper ones (more than 10) algorithmic advances in gradient propagation was needed. The main advantage of using deep neural networks is that they find their own feature representations of the given data. \acrfull{ai} promises that if you have enough data you can find any relation. However this is not always the case. Often you have noise, non stationary system (e.g. climate) and/or miss-labeled data. The last  being a consequence of humans labelling data. Earth system monitoring provides a global view of variables across meteorological systems. %\textbf{Some thing about satellite era}. These large amounts of data and the flexible nature of the neural network makes is a suitable method also in geosciences. \textbf{With enough data neural networks can serve as a universal function approximate given a suitable hyper parameter tuning and input data.} 




