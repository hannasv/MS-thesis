\chapter{Discussion - currently inspo}
\section{INSPO}
\begin{enumerate}
    \item No further adjustment is needed for a proper comparison.
\end{enumerate}

Siter Schubenau og si at satelitter definerer skyer basert på optical depth og at det derfor er nokså stor forskjellen på global gjennomsnittlig skydekket. I tillegg har man forskjeller på retrival algorithmns and sensors. 

\subsection{NOTES -- to be removed}
I dagen klima vet vi at skyer er vektig
Wild et al 2019 radiative budget.

Usikkerhet for fremtidig klima.
IPCC for klimafølsomhet og endringer i sky regimer. 

Manaby and Waetherall 1967 og (75?). første klimamodeller 
Hansen et al 1984.

Arrenius 1896 og tyndal 1861 fourier 1827.

cloud regimes from satelite images. What to expect in Europe. 

Figur forrig ipcc rapport. 

\begin{itemize}
    \item Sitere the earth machine. Si at machinlæring for stadig mer oppmerksomhet innenfor klimaforsning. 
    \item Snakke generelt om machine læring og artikkelen the measure of intelligence. 
    \item We’ll come back to this in section 2.1.5.
    \item Is out of the scope of this thesis.
    \item To abbreviate the notation for the cross-entropy the loss function is used, so we can rewrite eq. (6) into
    \item The distribution of values
    by feature is shown in fig. 2.
    \item Create correlation matrix using 
    \item We will keep in mind both the scores of 0.743 and 0.782, serving
    as fair baselines for a very simple, and slightly more sophisticated
    regression fit, respectively.
    \item Plotting R2 vs epoch, set ylim to 0,1. Not interresting to see where it learns.
    \item Summaries the best five architecture 
    \item A drawback of introducing more layers
    is that it increases the complexity, and thereby the chance of
 \end{itemize}


Advances in making deep learning possible:
\begin{enumerate}
    %\item Data availability, internet 
    %\item Hardware, engineering science (unlike mathematics and physics where advances can be made using pen and paper) - GPUs from gaming
    %\item Flexibility of neural networks makes it useful for fields ranging from self-driving cars, face generation and cancer detection. 
    %\item Probabilistic modelling and neural nets.
    \item Each layer learn the representation of the previous layer. 
    \item Deep networks can find relations in complex datasets this removed the need for feature representations and 
    \item classification + natural language processing --> image captioning. Getting the machine to write a sentence describing the image.
    \item Bottlenecks - rediscoveries backpropagation algorithmn and gradient descent. Can take any loss surface and move down the gradient toward a minimum. 
    \item k nearest neighbour, easy to explain - one of the first classification algoritmns.
    \item convolution - 2010 - works with every perceptual task - task involving learning something 
    \item solving pde's
    \item emulating other -- increasing speed while mimicking other models.
\end{enumerate}

\section{Good phases}
\begin{itemize}
    \item  In its most simple form, the diffusion equation is given by
    \item By using a finer grid one can usually get better approximations
    \item The comparison will focus on computational time and accuracy.
    \item This was chosen after
studying the development of the loss function as a function of number of iterations
    \item and is mandatory in
more advanced architectures(e.g. residual nets) where a constant spatial
dimension is demanded.
    \item a list of examples and so forth.
    \item (I will reference to source code/project part where relevant!)
    \item out of sample precision.
    \item Learn how to create plots with a zoomed in view.
    \item sufficiently large
    \item Viktig poeng. \textit{However, both academic
researchers and practitioners alike acknowledge the
need to make tests on the actual data set that is
subject of interest, as well as dedicating time and
resources to tune hyper parameters}
    \item methods for tabular data vs images
    \item I have opted to use
    \item We have also modified our own code for a dense feed forward neural
network produced for Project 2, see

\end{itemize}
