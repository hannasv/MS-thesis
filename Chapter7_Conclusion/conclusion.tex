\chapter{Conclusions}
% \textbf{Det du skal svare p√• fra Introduksjon, The scope of this study is to implement and compare different methods for data driven learning to find the most suitable method for cloud cover predictions.}
In this study a high quality dataset, \acrfull{ecc} was compiled for the purpose of performing data-driven learning on cloud cover. Two models, \acrfull{ar} and \acrlong{convlstm} models were built and evaluated based on their ability to predict a sequence of cloud cover.

The fist objective in this study, was to generate a high quality dataset. Without this the proposed methods are useless. The second objective was to build, train and evaluate the statistical models. 

Alternative, at its current state, inhomogenities renders, \acrshort{ecc}, inappropriate for cloud cover forecasting. This is not the same as stating its of low quality, however its not suitable for the applications in this study. 

If the results are bad, the conclusion is that the dataset is not of high enough quality. This is not uncommon when working with cloud data. Don't make it look like you took bad choices when building the dataset it may simply mean that the nature of the problem is difficult. Which it is..



\section{Summary of contributions and main findings }
The computational experiments conducted in this thesis lead to the following findings. 
\begin{enumerate}
    \item The \acrfull{awrs}
    \item Finished compiled dataset, ECC
\end{enumerate}

This study have contributed with the following contributions.
\begin{enumerate}
    \item Compiled dataset 
    \item Software for generating cloud fraction based satelite imiages from meteosat. Can be applied to other geostationary satelites and to other grid resolutions by regenerating the json files.
    \item Something on the models. 
    \item Framework for comparing AR-models and ConvLSTM.
\end{enumerate}

This study shows that model X performed best. However, since such few experiments was conducted it is important to underline the potential of further development of this models. Both efficiency for regression case, and automatic hyperparameter tuning for the machine learning models. Using the keras tuner, it is made available for the reader in the project GitHub repo. It is not performed in this study due to time limitiation and limited computational resources. But here lies great potential to find the best machine learning model. 

In the case of bad model performance. In conclusion, a higher quality dataset is necessary to apply these sets of models to the cloud forecasting problem. The models are state-of-the-art 

Advances in hardware, algorithms and X drive advances in machine learning, as mentioned in Section \ref{sec:ai}. %The optimal solution may have always been out of reach. 

\section{Future work}
A reasonable accurate model, may prove to have a practical application even though the \acrshort{mae} is imperfect. Evaluate the parameterisation in the context of a climate model.Using the output of the relevant variables from a \acrshort{ESM} ... \textbf{Trude they all have these variables right?}

Based on the small set of experiments run in this section, there is 
Datasets publish have different versions. Propose a suggestion for the content on \acrshort{ecc} v2.

Invest more effort in predicting longer sequences. Climate models usually make projections hundreds of years into the future.

In future work it would be interesting to asses how data driven parametrisation compare to the existing parametrizations available in the state of the art climate models. Here both the temporal and spatial resolution is a lot coarser. Other data sets could be considered. The masks in other data sets are computed based on more channels than in METeosat but the temporal resolution is a lot worse. 

Unfortunately, the best model is not sufficiently accurate to predict cloud cover. 

For future work it would be interesting to investigate how ..?

demonstrate its advantage and outperform ..?